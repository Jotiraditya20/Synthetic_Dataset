{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jotir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Class-wise Evaluation:\n",
      "\n",
      "Class: IMAGE\n",
      "True Positives (TP): 191\n",
      "False Positives (FP): 45\n",
      "False Negatives (FN): 116\n",
      "Background Predictions: 45\n",
      "Precision: 0.8093\n",
      "Recall: 0.6221\n",
      "\n",
      "Class: TEXT\n",
      "True Positives (TP): 2455\n",
      "False Positives (FP): 416\n",
      "False Negatives (FN): 2390\n",
      "Background Predictions: 416\n",
      "Precision: 0.8551\n",
      "Recall: 0.5067\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "IMAGE_FOLDER = r\"C:\\Users\\jotir\\Downloads\\train-2\\images\"\n",
    "LABEL_FOLDER = r\"C:\\Users\\jotir\\Downloads\\train-2\\labels\"\n",
    "MODEL_PATH = \"runs/detect/small_real/weights/last.pt\"\n",
    "IOU_THRESHOLD = 0.3\n",
    "MERGE_IOU_THRESHOLD = 0.0\n",
    "\n",
    "CLASS_NAMES = {0: \"image\", 1: \"text\"}\n",
    "\n",
    "# ==== IOU + Merging ====\n",
    "def box_iou(boxA, boxB):\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    "    inter = max(0, xB - xA) * max(0, yB - yA)\n",
    "    if inter == 0:\n",
    "        return 0.0\n",
    "    areaA = (boxA[2] - boxA[0]) * (boxA[3] - boxA[1])\n",
    "    areaB = (boxB[2] - boxB[0]) * (boxB[3] - boxB[1])\n",
    "    return inter / (areaA + areaB - inter)\n",
    "\n",
    "def merge_boxes_with_classes(boxes, classes, iou_thresh):\n",
    "    merged = []\n",
    "    used = [False] * len(boxes)\n",
    "    for i, (boxA, clsA) in enumerate(zip(boxes, classes)):\n",
    "        if used[i]:\n",
    "            continue\n",
    "        group = [boxA]\n",
    "        group_cls = clsA\n",
    "        used[i] = True\n",
    "        for j, (boxB, clsB) in enumerate(zip(boxes, classes)):\n",
    "            if not used[j] and clsA == clsB and box_iou(boxA, boxB) > iou_thresh:\n",
    "                group.append(boxB)\n",
    "                used[j] = True\n",
    "        group = np.array(group)\n",
    "        x1, y1 = np.min(group[:, 0:2], axis=0)\n",
    "        x2, y2 = np.max(group[:, 2:4], axis=0)\n",
    "        merged.append((group_cls, [x1, y1, x2, y2]))\n",
    "    return merged\n",
    "\n",
    "def load_gt_boxes(label_path, img_w, img_h):\n",
    "    boxes = []\n",
    "    classes = []\n",
    "    if not os.path.exists(label_path):\n",
    "        return boxes, classes\n",
    "    with open(label_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls, xc, yc, w, h = map(float, parts)\n",
    "            x1 = (xc - w / 2) * img_w\n",
    "            y1 = (yc - h / 2) * img_h\n",
    "            x2 = (xc + w / 2) * img_w\n",
    "            y2 = (yc + h / 2) * img_h\n",
    "            boxes.append([x1, y1, x2, y2])\n",
    "            classes.append(int(cls))\n",
    "    return boxes, classes\n",
    "\n",
    "\n",
    "metrics = {\n",
    "    0: {'TP': 0, 'FP': 0, 'FN': 0, 'BG': 0},  # image\n",
    "    1: {'TP': 0, 'FP': 0, 'FN': 0, 'BG': 0},  # text\n",
    "}\n",
    "\n",
    "model = YOLO(MODEL_PATH)\n",
    "\n",
    "for fname in os.listdir(IMAGE_FOLDER):\n",
    "    if not fname.lower().endswith(('.jpg', '.png', '.jpeg')):\n",
    "        continue\n",
    "\n",
    "    image_path = os.path.join(IMAGE_FOLDER, fname)\n",
    "    label_path = os.path.join(LABEL_FOLDER, os.path.splitext(fname)[0] + \".txt\")\n",
    "    img = cv2.imread(image_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Predictions\n",
    "    results = model(image_path, conf=0.8, show=False, verbose=False)[0]\n",
    "    if results.boxes is not None:\n",
    "        preds_raw = results.boxes.xyxy.cpu().numpy()\n",
    "        pred_classes = results.boxes.cls.cpu().numpy().astype(int)\n",
    "    else:\n",
    "        preds_raw = []\n",
    "        pred_classes = []\n",
    "\n",
    "    merged_preds = merge_boxes_with_classes(preds_raw, pred_classes, MERGE_IOU_THRESHOLD)\n",
    "\n",
    "    # Ground truth\n",
    "    gts, gt_classes = load_gt_boxes(label_path, w, h)\n",
    "    gt_used = [False] * len(gts)\n",
    "    pred_used = [False] * len(merged_preds)\n",
    "\n",
    "    for i, (pred_cls, pred_box) in enumerate(merged_preds):\n",
    "        for j, (gt_box, gt_cls) in enumerate(zip(gts, gt_classes)):\n",
    "            if pred_cls == gt_cls and not gt_used[j] and box_iou(pred_box, gt_box) >= IOU_THRESHOLD:\n",
    "                metrics[pred_cls]['TP'] += 1\n",
    "                gt_used[j] = True\n",
    "                pred_used[i] = True\n",
    "                break\n",
    "\n",
    "    for i, (pred_cls, _) in enumerate(merged_preds):\n",
    "        if not pred_used[i]:\n",
    "            metrics[pred_cls]['FP'] += 1\n",
    "            metrics[pred_cls]['BG'] += 1\n",
    "\n",
    "    for j, gt_cls in enumerate(gt_classes):\n",
    "        if not gt_used[j]:\n",
    "            metrics[gt_cls]['FN'] += 1\n",
    "\n",
    "# ==== OUTPUT ====\n",
    "print(\"\\nðŸ“Š Class-wise Evaluation:\")\n",
    "for cls_id, name in CLASS_NAMES.items():\n",
    "    TP = metrics[cls_id]['TP']\n",
    "    FP = metrics[cls_id]['FP']\n",
    "    FN = metrics[cls_id]['FN']\n",
    "    BG = metrics[cls_id]['BG']\n",
    "    precision = TP / (TP + FP + 1e-6)\n",
    "    recall = TP / (TP + FN + 1e-6)\n",
    "\n",
    "    print(f\"\\nClass: {name.upper()}\")\n",
    "    print(f\"True Positives (TP): {TP}\")\n",
    "    print(f\"False Positives (FP): {FP}\")\n",
    "    print(f\"False Negatives (FN): {FN}\")\n",
    "    print(f\"Background Predictions: {BG}\")\n",
    "    print(f\"Precision: {precision:.4f}\")\n",
    "    print(f\"Recall: {recall:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "MODEL_PATH = \"runs/detect/train12/weights/last.pt\"  \n",
    "DATA_YAML = \"data_test.yaml\"     \n",
    "CONF_THRESHOLD = 0.9      \n",
    "def evaluate_model(model_path, data_yaml):\n",
    "    print(f\"Evaluating model: {model_path}\")\n",
    "    model = YOLO(model_path)\n",
    "\n",
    "    metrics = model.val(\n",
    "        data=data_yaml,\n",
    "        split='test',\n",
    "        conf=CONF_THRESHOLD,\n",
    "        iou = 1,\n",
    "        save_json=True,\n",
    "        save_hybrid=True\n",
    "    )\n",
    "\n",
    "    print(\"\\n---- RESULTS ----\")\n",
    "    print(f\"mAP50: {metrics.box.map50:.4f}\")\n",
    "    print(f\"mAP50-95: {metrics.box.map:.4f}\")\n",
    "    print(f\"Precision: {metrics.box.mp:.4f}\")\n",
    "    print(f\"Recall: {metrics.box.mr:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_model(MODEL_PATH, DATA_YAML)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
